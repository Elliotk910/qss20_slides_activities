{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 (30 points)\n",
    "\n",
    "Use the same `sentencing_cleaned` data from Problem Set 1 for this assignment. You can either read in the pkl or csv but if csv, follow the instructions in the Github issue here to recast some columns as datetime: https://github.com/rebeccajohnson88/qss20_slides_activities/issues/6#issuecomment-1013546655\n",
    "\n",
    "In Problem Set 1, you investigated one form of disparity in the US criminal justice system: probation versus incarceration.\n",
    "\n",
    "Here, you'll investigate a second type of disparity---the length of a defendant's sentence---and also investigate the disparities faced by defendants sentenced by the same judge for the same crime. \n",
    "\n",
    "As a reminder, the codebook is available at this link:  https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read in the data and filter to defendants who were incarcerated and construct a sentence length variable (14 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in the data\n",
    "- Filter to sentences that involve incarceration (same Illinois Department of Corrections logic as in problem set one: \n",
    "incarceration is indicated by `COMMITMENT_TYPE` == \"Illinois Department of Corrections\")\n",
    "- Using the `COMMITMENT_UNIT` column that represents sentence length, filter out the following non-numeric sentence lengths: Term, Pounds, Dollars, Ounces (year, months, natural life, days, hours, and weeks should remain)\n",
    "- Filter to Black or White defendants\n",
    "\n",
    "**Concepts tested and resources**: this question tests filtering rows based on logical conditions. Here are some resources:\n",
    "- DataCamp on .loc: https://campus.datacamp.com/courses/data-manipulation-with-pandas/slicing-and-indexing-dataframes?ex=3\n",
    "- Lecture 2 slide 19: https://campus.datacamp.com/courses/data-manipulation-with-pandas/slicing-and-indexing-dataframes?ex=3 \n",
    "- Row subsetting section in this activity: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hints on output**: we get 58289 rows remaining after this filtering. Don't worry about matching this exactly but try to get in the ballpark range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here that reads in data and filters the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, follow the instructions in the codebook (combining `COMMITMENT_TERM` with `COMMITMENT_UNIT`) to create a standard sentence length in days column (`senlength_derived`) that measures the sentence in **days**. To simplify, you can assume that:\n",
    "\n",
    "- 1 hour = 1/24th of a day\n",
    "- 1 year = 365 days\n",
    "- 1 month = 30.5 days\n",
    "- 1 week = 7 days\n",
    "- Natural life = difference between the age of 100 and the defendant's age at incident (cleaned; if missing, code to age 20); note that this is a simplification since age at incident != age at sentencing \n",
    "\n",
    "Print the following cols for an example of each type (eg an example of originally hours; an example of natural life): `COMMITMENT_TERM`, `COMMITMENT_UNIT`, `age_derived` and your new standardized sentence length column (`senlength_derived`)\n",
    "\n",
    "Print the summary of that column (`senlength_derived`) using the .describe() command\n",
    "\n",
    "**Concepts tested and resources**: there are many approaches but a couple ways are:\n",
    "- np.select covered in the slides and this activity notebook: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb \n",
    "- writing a function that takes in one row as an argument and has a series of if, elif, else conditions where different commitment_units are translated into days. To execute this function, you can use the .apply function but apply it with axis = 1 (row-wise). Resources for that include: (1) the activity notebook on user-defined functions (https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/02_loopsfunctions_solutions.ipynb); (2) the activity notebook covering apply: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hint on output**: see GitHub issue for the summary stats we get from running .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here on translation of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here on printing example of each type of committment unit and what it's senlength_derived is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here with the .describe() command summary of the senlength_derived column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Examine disparities in length within the same judge and offense category: constructing matched pairs (16 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the above ~58k row dataset that is subsetted to only to sentences involving incarceration. Then, further subset the rows to:\n",
    "- Rows where `judgeid_derived` = `judge_21` \n",
    "- `simplified_offense_derived` == \"Narcotics\"\n",
    "\n",
    "Use `shape` to print the dimensions of the resulting dataframe\n",
    "\n",
    "**Concepts and resources**: row subsetting using logical conditions; see above resources\n",
    "\n",
    "**Hint on output**: we get 53 rows after this filtering step. Don't worry about matching this exactly but try to get in the ballpark range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to filter rows and check the shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "For each defendant sentenced by judge_21, you want to construct a \"matched group\" of defendants who:\n",
    "\n",
    "- Are the same exact age as the focal defendant (`age_derived`) and\n",
    "- Are the same gender as the focal defendant (`is_male_derived`) but \n",
    "- Differ in race from the focal defendant (`is_black_derived`/`is_white_derived`)\n",
    "\n",
    "Write a user-defined function to find any/all matched defendants for each focal defendant of judge 21. You can structure the function in various ways but one way is to write a function similar to the class example where we iterate over different DC crimes (focal crimes) and find similar crimes. For this problem, we want to:\n",
    "\n",
    "- Iterate over unique defendants sentenced by judge 21 (use `CASE_PARTICIPANT_ID` to identify each unique defendant)\n",
    "- Find other defendants in the judge 21 pool who (1) have a different race from that focal defendant but (2) the same gender and age \n",
    "\n",
    "\n",
    "**Concepts and resources**: \n",
    "\n",
    "- Slides and activity code on user-defined functions and iterating using list comprehension: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/02_loopsfunctions_solutions.ipynb\n",
    "- You can either write code in the function to add columns with the attributes of the focal defendant (existing material) or using `pd.merge` to join these on after; we'll be covering `pd.merge` Monday 01.24 but here are last year's slides (slide 17-20) in meantime: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/s21_slides/qss20_s21_class4.pdf \n",
    "\n",
    "\n",
    "**Hints on output**: \n",
    "\n",
    "- Some focal defendants may not have any matches; they can be excluded from the results \n",
    "- In the way we wrote our function, each iteration of the function returns a single dataframe; because we execute via list comprehension, the output of this step is a list of dataframes (it's okay if you take a diff approach!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to execute the function for all defendants sentenced by judge_21 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from Part B, use `pd.concat` or another approach to create a dataframe that compares the (1) race and sentence length for the focal defendant to (2) the sentence length for other defendants. Using this dataframe, show this comparison for focal defendant: `CASE_PARTICIPANT_ID` == `808109112733`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code to rowbind all matches and to highlight the comparison\n",
    "## for the example defendant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from Part C, group by the focal defendant's race and find the proportion of that defendant's matches who had a LONGER sentence than the focal defendant\n",
    "\n",
    "**Concepts and resources**: can use groupby and agg\n",
    "\n",
    "- Groupby and agg code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hints on output**: since we're grouping by race in the full pool, the resulting output should have two values: one for the rate at which Black defendants have matches with higher sentences; another for the rate at which White defendants have matches with higher sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 1-2 lines commenting on the results from Part D. What other defendant or offense-level characteristics would you like to match on to investigate claims about racial disparities? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optional extra credit/challenge exercise (2 points): examine disparities across multiple judges\n",
    "\n",
    "In problem 1.2, we focused on one judge: judge 21.\n",
    "    \n",
    "For this extra credit exercise, use the same data filtered to (1) incarceration, (2) Black/White only, and (3) narcotics offenses. \n",
    "    \n",
    "- Get judges with a high enough sample of each group to compare sentencing: filter to each judge with at least 20 Black and at least 20 white defendants\n",
    "- For each of the judges, calculate the median sentence length for their Black defendants and (2) the median sentence length for their white defendants \n",
    "- Create a barplot with the result: factor variable on x axis for each judge_id who qualifies; separate bars/colors by race\n",
    "- Write a 1-2 sentence interpretation - if we assume that cases/defendants are randomly assigned to sentencing judges, what might this suggest about the role of judicial discretion in these disparities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optional extra credit/challenge exercise (2 points): impute possible demographic correlate of sentencing\n",
    "\n",
    "The previous exercises showed large differences in sentences between judges/differences in disparities. You become interested in how the judge's own demographic attributes are correlated with sentencing. Going back to the judge's name (`SENTENCE JUDGE`), parse their first name and try to probabilistically infer his or her gender. Then, investigate whether disparities differ between \"likely female\" and \"likely male\" judges. \n",
    "\n",
    "**Note on ethics of probabilistic inference of attributes based on name**: Using names to infer demographic characteristics has become increasingly popular with the rise of \"digital trace data\" that often lacks explicit demographic fields (e.g., tweets just have usernames and profiles; academic citation networks just have author names). But there are many valid ethical critiques of this practice. In the case of gender, a person's assigned name at birth clearly does not always map onto their self-identified gender, both due to genders beyond the binary of male/female and names like \"Morgan.\" A couple critiques I link to are:\n",
    "\n",
    "- [This blog post](https://scatter.wordpress.com/2021/07/30/who-writes-social-science/)\n",
    "- [Urban Institute ethical risks of race/ethnicity imputation - applies to gender](https://www.urban.org/research/publication/five-ethical-risks-consider-filling-missing-race-and-ethnicity-data)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
