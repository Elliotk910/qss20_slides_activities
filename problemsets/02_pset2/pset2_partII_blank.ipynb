{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "## nltk imports\n",
    "import nltk\n",
    "### uncomment and run these lines if you haven't downloaded relevant nltk add-ons yet\n",
    "### nltk.download('averaged_perceptron_tagger')\n",
    "### nltk.download('stopwords')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## spacy imports\n",
    "import spacy\n",
    "### uncomment and run the below line if you haven't loaded the en_core_web_sm library yet\n",
    "### ! python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "## vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## sentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "## lda\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text analysis of DOJ press releases\n",
    "\n",
    "For background, here's the Kaggle that contains the data: https://www.kaggle.com/jbencina/department-of-justice-20092018-press-releases \n",
    "\n",
    "Here's the code the dataset owner used to scrape those press releases here if you're interested: https://github.com/jbencina/dojreleases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics_clean</th>\n",
       "      <th>components_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Convicted Bomb Plotter Sentenced to 30 Years</td>\n",
       "      <td>PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...</td>\n",
       "      <td>2014-10-01T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>National Security Division (NSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-919</td>\n",
       "      <td>$1 Million in Restitution Payments Announced t...</td>\n",
       "      <td>WASHINGTON – North Carolina’s Waccamaw River...</td>\n",
       "      <td>2012-07-25T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1002</td>\n",
       "      <td>$1 Million Settlement Reached for Natural Reso...</td>\n",
       "      <td>BOSTON– A $1-million settlement has been...</td>\n",
       "      <td>2011-08-03T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-015</td>\n",
       "      <td>10 Las Vegas Men Indicted \\r\\nfor Falsifying V...</td>\n",
       "      <td>WASHINGTON—A federal grand jury in Las Vegas...</td>\n",
       "      <td>2010-01-08T00:00:00-05:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0     None       Convicted Bomb Plotter Sentenced to 30 Years   \n",
       "1  12-919   $1 Million in Restitution Payments Announced t...   \n",
       "2  11-1002  $1 Million Settlement Reached for Natural Reso...   \n",
       "3   10-015  10 Las Vegas Men Indicted \\r\\nfor Falsifying V...   \n",
       "4   18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...   \n",
       "1    WASHINGTON – North Carolina’s Waccamaw River...   \n",
       "2        BOSTON– A $1-million settlement has been...   \n",
       "3    WASHINGTON—A federal grand jury in Las Vegas...   \n",
       "4  The U.S. Department of Justice, the U.S. Envir...   \n",
       "\n",
       "                        date topics_clean  \\\n",
       "0  2014-10-01T00:00:00-04:00     No topic   \n",
       "1  2012-07-25T00:00:00-04:00     No topic   \n",
       "2  2011-08-03T00:00:00-04:00     No topic   \n",
       "3  2010-01-08T00:00:00-05:00     No topic   \n",
       "4  2018-07-09T00:00:00-04:00  Environment   \n",
       "\n",
       "                             components_clean  \n",
       "0            National Security Division (NSD)  \n",
       "1  Environment and Natural Resources Division  \n",
       "2  Environment and Natural Resources Division  \n",
       "3  Environment and Natural Resources Division  \n",
       "4  Environment and Natural Resources Division  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run this code to load the unzipped json file and convert to a dataframe\n",
    "## and convert some of the things from lists to values\n",
    "doj = pd.read_json(\"../../public_data/combined.json\", lines = True)\n",
    "\n",
    "## due to json, topics are in a list so remove them and concatenate with ;\n",
    "doj['topics_clean'] = [\"; \".join(topic) \n",
    "                      if len(topic) > 0 else \"No topic\" \n",
    "                      for topic in doj.topics]\n",
    "\n",
    "## similarly with components\n",
    "doj['components_clean'] = [\"; \".join(comp) \n",
    "                           if len(comp) > 0 else \"No component\" \n",
    "                           for comp in doj.components]\n",
    "\n",
    "## drop older columns from data\n",
    "doj = doj[['id', 'title', 'contents', 'date', 'topics_clean', 'components_clean']].copy()\n",
    "\n",
    "doj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 NLP on one press release (10 points)\n",
    "\n",
    "Focus on the following press release: `id` == \"17-1204\" about this pharmaceutical kickback prosecution: https://www.forbes.com/sites/michelatindera/2017/11/16/fentanyl-billionaire-john-kapoor-to-plead-not-guilty-in-opioid-kickback-case/?sh=21b8574d6c6c \n",
    "\n",
    "The `contents` column is the one we're treating as a document. You may need to to convert it from a pandas series to a single string.\n",
    "\n",
    "\n",
    "- Part of speech tagging- extract verbs and sort from most occurrences to least occurrences\n",
    "- Named entity recognition --- what are the different organizations mentioned? how would you like to make more granular?\n",
    "- Sentence level versus document-level sentiment scoring\n",
    "\n",
    "- For sentence level scoring, print a few top positive and top negative. Does the automatic classifier seem to work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1: part of speech tagging (3 points)\n",
    "\n",
    "A. Preprocess the press release to remove all punctuation / digits (so can subset to one_word.isalpha())\n",
    "\n",
    "B. Then, use part of speech tagging within nltk to tag all the words in that one press release with their part of speech. \n",
    "\n",
    "C. Finally, extract the adjectives and sort those adjectives from most occurrences to fewest occurrences. Print the 5 most frequent adjectives. See here for a list of the names of adjectives within nltk: https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Documentation for .isalpha(): https://www.w3schools.com/python/ref_string_isalpha.asp\n",
    "- `processtext` function here has an example of tokenizing and filtering to words where .isalpha() is true: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partII_topicmodeling_solution.ipynb \n",
    "- Part of speech tagging section of this code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partI_textmining_examplecode.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 named entity recognition (3 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Using the alpha-only press release you created in the previous step, use spaCy to extract all named entities from the press release\n",
    "\n",
    "B. Print all the named entities along with their tag\n",
    "\n",
    "C. You want to extract the possible sentence lengths the CEO is facing; pull out the named entities with (1) the label `DATE` and (2) that contain the word year or years (hint: you may want to use the `re` module for that second part). Print these.\n",
    "\n",
    "D. Pull and print the original parts of the press releases where those year lengths are mentioned (e.g., the sentences or rough region of the press release). Describe in your own words (1 sentence) what length of sentence (prison) and probation (supervised release) the CEO may be facing if convincted after this indictment.\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Named entity recognition part of this code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partI_textmining_examplecode.ipynb\n",
    "- re.search and re.findall examples here for filtering to ones containing year (multiple approaches; some need not involve `re`): https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/04_basicregex_formerging.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Sentiment analysis (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Use a `SentimentIntensityAnalyzer` and `polarity_scores` to score the entire press release for its sentiment (you can go back to the raw string of the press release without punctuation/digits removed)\n",
    "\n",
    "B. Remove all named entities from the string and score the sentiment of the press release without named entities. Did the neutral score go up or down relative to the version of the press release containing named entities? Why do you think this occurred?\n",
    "\n",
    "C. With the version of the string that removes named entities, try to split the press release into discrete sentences (hint: re.split() may be useful since it allows or conditions in the pattern you're looking for). Print the first 5 sentences of the split press release (there will not be deductions if there remain some erroneous splits; just make sure it's generally splitting)\n",
    "\n",
    "D. Score each sentence in the split press release and print the top 5 sentences in the press release with the most negative sentiment (use the `neg` score- higher values = more negative). **Hint**: you can use pd.DataFrame to rowbind a list of dictionaries; you can then add the press release sentence for each row back as a column in that dataframe and use sort_values()                                                  \n",
    "                \n",
    "**Resources**:\n",
    "\n",
    "- Sentiment analysis section of this script: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partI_textmining_examplecode.ipynb\n",
    "\n",
    "- Discussion of using `re.split()` to split on multiple delimiters: https://stackoverflow.com/questions/4998629/split-string-with-multiple-delimiters-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 sentiment scoring across many press releases (10 points)\n",
    "\n",
    "\n",
    "A. Subset the press releases to those labeled with one of free topics (can just do if topic_clean == that topic rather than finding where that topic is mentioned in a longer list): Civil Rights, Hate Crimes, and Project Safe Childhood. We'll call this `doj_subset` going forward and it should have 717 rows.\n",
    "\n",
    "B. Write a function that takes one press release string as an input and:\n",
    "\n",
    "- Removes named entities from each press release string\n",
    "- Scores the sentiment of the entire press release\n",
    "\n",
    "Apply that function to each of the press releases in `doj_subset`. \n",
    "\n",
    "**Hints**: \n",
    "\n",
    "- You may want to use re.escape at some point to avoid errors relating to escape characters like ( in the press release\n",
    "- I used a function + list comprehension to execute and it takes about 30 seconds on my local machine and about 2 mins on jhub; if it's taking a very long time, you may want to check your code for inefficiencies. If you can't fix those, for partial credit on this part/full credit on remainder, you can take a small random sample\n",
    "\n",
    "C. Add the scores to the `doj_subset` dataframe. Sort from highest neg to lowest neg score and print the top 5 most neg.\n",
    "\n",
    "D. With that dataframe, find the mean compound score for each of the three topics using group_by and agg. Add a 1 sentence interpretation of why we might see the variation in scores (remember that compound is a standardized summary where -1 is most negative; +1 is most positive)\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Same named entity and sentiment resources as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 topic modeling (25 points)\n",
    "\n",
    "For this question, use the `doj_subset` data that is reestricted to civil rights, hate crimes, and project safe childhood and with the sentiment scores added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Preprocess the data by removing stopwords, punctuation, and non-alpha words (5 points)\n",
    "\n",
    "A. Write a function that:\n",
    "\n",
    "- Takes in each of the raw strings in the `contents` column from that dataframe\n",
    "- Does the following preprocessing steps:\n",
    "\n",
    "    - Converts the words to lowercase\n",
    "    - Removes stopwords, adding the custom stopwords in your code cell below to the default stopwords list\n",
    "    - Only retains alpha words (so removes digits and punctuation)\n",
    "    - Only retains words 4 characters or longer\n",
    "    - Uses the snowball stemmer from nltk to stem\n",
    "    \n",
    "B. Print the preprocessed text for the following press releases:\n",
    "\n",
    "id = 16-718 (this case: https://www.seattletimes.com/nation-world/doj-miami-police-reach-settlement-in-civil-rights-case/)\n",
    "\n",
    "id = 16-217 (this case: https://www.wlbt.com/story/32275512/three-mississippi-correctional-officers-indicted-for-inmate-assault-and-cover-up/)\n",
    "    \n",
    "**Resources**:\n",
    "\n",
    "- Here's code examples for the snowball stemmer: https://www.geeksforgeeks.org/snowball-stemmer-nlp/\n",
    "- Here's more condensed code with topic modeling steps: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partII_topicmodeling_solution.ipynb \n",
    "- Here's longer code with more broken-out topic modeling steps: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partII_topicmodeling_examplecode.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_doj_stopwords = [\"civil\", \"rights\", \"division\", \"department\", \"justice\",\n",
    "                        \"office\", \"attorney\", \"district\", \"case\", \"investigation\", \"assistant\",\n",
    "                       \"trial\", \"assistance\", \"assist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Create a document-term matrix from the preprocessed press releases and to explore top words (5 points)\n",
    "\n",
    "A. Use the `create_dtm` function I provide (alternately, feel free to write your own!) and create a document-term matrix using the preprocessed press releases; make sure metadata contains the `compound` sentiment column you added and the `topics_clean` column\n",
    "\n",
    "B. Print the top 10 words for press releases with compound sentiment in the top 5% (so most positive)\n",
    "\n",
    "C. Print the top 10 words for press releases with compound sentiment in the bottom 5% (so most negative)\n",
    "\n",
    "**Hint**: for these, remember the pandas quantile function from pset one.  \n",
    "\n",
    "D. What are the top 10 words for press releases in each of the three `topics_clean`?\n",
    "\n",
    "For steps B - D, to receive full credit, write a function `get_topwords` that helps you avoid duplicated code when you find top words for the different subsets of the data\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Here contains an example of applying the create_dtm function: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partII_topicmodeling_examplecode.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names())\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Estimate a topic model using those preprocessed words (5 points)\n",
    "\n",
    "A. Going back to the preprocessed words from part 2.3.1, estimate a topic model with 3 topics, since you want to see if the unsupervised topic models recover different themes for each of the three manually-labeled areas (civil rights; hate crimes; project safe childhood). You have free rein over the other topic model parameters beyond the number of topics.\n",
    "\n",
    "B. After estimating the topic model, print the top 15 words in each topic.\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Same topic modeling resources linked to above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Add topics back to main data and explore correlation between manual labels and our estimated topics (10 points)\n",
    "\n",
    "A. Extract the document-level topic probabilities. Within `get_document_topics`, use the argument `minimum_probability` = 0 to make sure all 3 topic probabilities are returned. Write an assert statement to make sure the length of the list is equal to the number of rows in the `doj_subset` dataframe\n",
    "\n",
    "B. Add the topic probabilities to the `doj_subset` dataframe as columns and code each document to its highest-probability topic\n",
    "\n",
    "C. For each of the manual labels in `topics_clean` (Hate Crime, Civil Rights, Project Safe Childhood), print the breakdown of the % of documents with each top topic (so, for instance, Hate Crime has 246 documents-- if 123 of those documents are coded to topic_1, that would be 50%; and so on). **Hint**: pd.crosstab and normalize may be helpful: https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.crosstab.html\n",
    "\n",
    "D. Using a couple press releases as examples, write a 1-2 sentence interpretation of why some of the manual topics map on more cleanly to an estimated topic than other manual topic(s)\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- End of this code contains example of how to use `get_document_topics` and other steps to add topic probabilities back to data: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/06_textasdata_partII_topicmodeling_solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 OPTIONAL extra credit (5 points)\n",
    "\n",
    "You notice that the pharmaceutical kickbacks press release we analyzed in question 2.1 was for an indictment, and that in the original data, there's not a clear label for whether a press release outlines an indictment (charging someone with a crime), a conviction (convicting them after that charge either via a settlement or trial), or a sentencing (how many years of prison or supervised release a defendant is sentenced to after their conviction).\n",
    "\n",
    "You want to see if you can identify pairs of press releases where one press release is from one stage (e.g., indictment) and another is from a different stage (e.g., a sentencing).\n",
    "\n",
    "You decide that one way to approach is to find the pairwise string similarity between each of the processed press releases in `doj_subset`. There are many ways to do this, so Google for some approaches, focusing on ones that work well for entire documents rather than small strings. Feel free to load additional packages if needed\n",
    "\n",
    "Find the top two pairs (so four press releases total)-- do they seem like different stages of the same crime or just press releases covering similar crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
